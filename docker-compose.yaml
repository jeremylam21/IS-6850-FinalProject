version: '3.7'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - flink-net

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    ports:
      - "9092:9092"
      - "29092:29092"
    restart: unless-stopped
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,HOST://0.0.0.0:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper
    networks:
      - flink-net

  kafka-init:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - kafka
    entrypoint: [ "/bin/sh", "-c" ]
    command: |
      "
      echo 'Waiting for Kafka...';
      sleep 5;
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic stock_events --partitions 1 --replication-factor 1;
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic stock_anomalies --partitions 1 --replication-factor 1;
      echo 'Kafka topics initialized.';
      "
    networks:
      - flink-net

  flink-jobmanager:
    build:
      context: ./flink-anomaly-job
    image: flink-kafka-enabled:1.17
    container_name: flink-jobmanager
    restart: unless-stopped
    ports:
      - "8081:8081"
    environment:
      - FLINK_PLUGINS_DIR=/opt/flink/plugins
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    entrypoint: /app/entrypoint.sh
    depends_on:
      - kafka
    networks:
      - flink-net

  flink-taskmanager:
    build:
      context: ./flink-anomaly-job
    image: flink-kafka-enabled:1.17
    container_name: flink-taskmanager
    restart: unless-stopped
    depends_on:
      - flink-jobmanager
    environment:
      - FLINK_PLUGINS_DIR=/opt/flink/plugins
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    command: taskmanager
    networks:
      - flink-net

  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "8086:8086"
    volumes:
      - influxdb-data:/var/lib/influxdb2
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=supersecret
      - DOCKER_INFLUXDB_INIT_ORG=default-org
      - DOCKER_INFLUXDB_INIT_BUCKET=stock_data
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=mytoken
    networks:
      - flink-net

  anomaly-writer:
    build:
      context: ./influx-anomaly-writer
    depends_on:
      - kafka
      - influxdb
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=stock_anomalies
      - KAFKA_GROUP_ID=anomaly-writer-group
      - INFLUX_URL=http://influxdb:8086
      - INFLUX_BUCKET=stock_data
      - INFLUX_ORG=default-org
      - INFLUX_TOKEN=mytoken
    networks:
      - flink-net

  stock-writer:
    build:
      context: ./influx-event-writer
    depends_on:
      - kafka
      - influxdb
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=stock_events
      - KAFKA_GROUP_ID=event-writer-group
      - INFLUX_URL=http://influxdb:8086
      - INFLUX_BUCKET=stock_data
      - INFLUX_ORG=default-org
      - INFLUX_TOKEN=mytoken
    networks:
      - flink-net

  grafana:
    image: grafana/grafana:10.2.3
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - flink-net

volumes:
  influxdb-data:
  grafana-data:

networks:
  flink-net:
    name: flink-net

